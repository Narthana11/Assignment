{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1a9mzuQp5hJg7xv5hRfNUDdoI-J8EodNA",
      "authorship_tag": "ABX9TyNKH6HbuwVKtv2jKAdmkKzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Narthana11/Assignment/blob/main/Lab4_Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryLtUbQFPr-V"
      },
      "outputs": [],
      "source": [
        "import os; os.chdir('/content/drive/MyDrive/content')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Collection for The Assignment\n",
        "import os\n",
        "import csv\n",
        "\n",
        "audio_dir = \"audio\"\n",
        "csv_filename = \"audio/dataset.csv\"\n",
        "\n",
        "with open(csv_filename, mode=\"w\", newline=\"\") as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"filename\", \"label\"])\n",
        "\n",
        "    for label in os.listdir(audio_dir):\n",
        "        label_dir = os.path.join(audio_dir, label)\n",
        "\n",
        "        if os.path.isdir(label_dir):\n",
        "            for filename in os.listdir(label_dir):\n",
        "                if filename.endswith(\".wav\"):\n",
        "                    writer.writerow([filename, label])\n",
        "\n",
        "print(f\"CSV file '{csv_filename}' has been created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikpDXrV9Iodo",
        "outputId": "6b07ff71-628c-4080-9a8d-8bb9875a1574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file 'audio/dataset.csv' has been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CebwDJmuIpiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poHAN-rqP0-9",
        "outputId": "60ca0a90-7ba1-4837-f6fb-718f6ad85bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.6.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Jy3_73VHKe",
        "outputId": "a0061482-f4d4-4f65-c49d-038e873c3fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sox in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from sox) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from sox) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "data_dir = \"audio\"\n",
        "csv_file = \"audio/dataset.csv\"\n",
        "output_dir = \"trainingdata\"\n",
        "\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "\n",
        "for dataset, dataset_df in zip([\"train\", \"test\"], [train_df, test_df]):\n",
        "  for _, row in dataset_df.iterrows():\n",
        "    filename = row['filename']\n",
        "    label = row['label']\n",
        "\n",
        "    source_path = os.path.join(data_dir, label, filename)\n",
        "\n",
        "    destination_folder = os.path.join(output_dir, dataset, label)\n",
        "    os.makedirs(destination_folder, exist_ok=True)\n",
        "    destination_path = os.path.join(destination_folder, filename)\n",
        "    shutil.copy(source_path, destination_path)\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "test_df.to_csv(\"test.csv\", index=False)"
      ],
      "metadata": {
        "id": "ZayJSJF4wAeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomSpeechDataset(Dataset):\n",
        "    def __init__(self, csv_file, data_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.data.iloc[idx, 0]\n",
        "        label = self.data.iloc[idx, 1]\n",
        "\n",
        "        audio_path = os.path.join(self.data_dir, label, filename)\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "        if self.transform:\n",
        "            waveform = self.transform(waveform)\n",
        "\n",
        "        return waveform, sample_rate, label\n",
        "\n",
        "train_dataset = CustomSpeechDataset(csv_file=\"split/train_labels.csv\", data_dir=\"split/train/\")\n",
        "test_dataset = CustomSpeechDataset(csv_file=\"split/test_labels.csv\", data_dir=\"split/test/\")\n",
        "\n",
        "print(f\"Train Samples: {len(train_dataset)}, Test Samples: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-RYr8NjwjpF",
        "outputId": "5f4c0c62-a66c-409b-9afb-160e29d3552f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Samples: 192, Test Samples: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn  # Add this line\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class M5(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool1 = nn.MaxPool1d(4)\n",
        "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool2 = nn.MaxPool1d(4)\n",
        "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool3 = nn.MaxPool1d(4)\n",
        "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool4 = nn.MaxPool1d(4)\n",
        "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(self.bn4(x))\n",
        "        x = self.pool4(x)\n",
        "        x = F.avg_pool1d(x, x.shape[-1])\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x.squeeze(1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-tzwNBe9yQ_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "labels = set([d[2] for d in test_dataset])\n",
        "label2num = {label:num for num, label in enumerate(labels)}\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "  data = [b[0][0] for b in batch]\n",
        "  data = pad_sequence(data, batch_first=True)\n",
        "  labels = torch.LongTensor([label2num[b[2]] for b in batch])\n",
        "  return data, labels\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "x, y = next(iter(train_loader))\n",
        "x.shape, y\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KirEtBQ3_9lO",
        "outputId": "5b375dfc-4ca6-4a1e-c729-baa89106c4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 48000]),\n",
              " tensor([1, 3, 3, 0, 2, 0, 2, 1, 2, 3, 2, 1, 0, 2, 3, 2, 0, 1, 3, 0, 3, 1, 0, 1,\n",
              "         2, 1, 0, 1, 0, 1, 0, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "metadata": {
        "id": "AjPGnQx_BXFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, epoch):\n",
        "    model.train()\n",
        "    loss_train = AverageMeter()\n",
        "\n",
        "    acc_train = Accuracy(task=\"multiclass\", num_classes=4).to(device)\n",
        "\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for inputs, targets in tepoch:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train.update(loss.item(), inputs.size(0))\n",
        "            acc_train.update(preds, targets)\n",
        "\n",
        "            tepoch.set_postfix(loss=loss_train.avg, acc=acc_train.compute().item())\n",
        "\n",
        "    return model, loss_train.avg, acc_train.compute().item()\n"
      ],
      "metadata": {
        "id": "HgAYpABSBP2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cls = 35\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "labels = set([d[2] for d in test_dataset])\n",
        "label2num = {label:num for num, label in enumerate(labels)}\n",
        "print(label2num)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAUkMkZuMUQt",
        "outputId": "f898d64c-ebc7-4c0f-a917-d01815ff37d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'unknown': 0, 'orange': 1, 'cherry': 2, 'apple': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "  data = [b[0][0] for b in batch]\n",
        "  data = pad_sequence(data, batch_first=True)\n",
        "  labels = torch.LongTensor([label2num[b[2]] for b in batch])\n",
        "  return data, labels\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "x, y = next(iter(train_loader))\n",
        "x.shape, y\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18ulj4VxMfv_",
        "outputId": "06f95bd0-0597-457a-8d16-78ffa3ccb1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 48000]),\n",
              " tensor([0, 3, 3, 0, 1, 0, 1, 0, 3, 0, 0, 2, 2, 1, 2, 2, 1, 3, 3, 1, 0, 1, 3, 2,\n",
              "         3, 0, 2, 2, 3, 2, 0, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = set([d[2] for d in test_dataset])\n",
        "label2num = {label:num for num, label in enumerate(labels)}\n",
        "print(label2num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRZJiMEpNuEO",
        "outputId": "6ef21d01-4c5e-458a-87ff-023a2abac985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'unknown': 0, 'orange': 1, 'cherry': 2, 'apple': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "  data = [b[0][0] for b in batch]\n",
        "  data = pad_sequence(data, batch_first=True)\n",
        "  data = AF.resample(data, 16000, 8000).unsqueeze(1)\n",
        "  labels = torch.LongTensor([label2num[b[2]] for b in batch])\n",
        "  return data, labels\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "x, y = next(iter(train_loader))\n",
        "x.shape, y\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwMzL0cRNyd3",
        "outputId": "07851703-a51e-4858-d2a2-620c20ec5753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 24000]),\n",
              " tensor([3, 1, 2, 2, 0, 0, 1, 3, 1, 1, 0, 3, 1, 2, 1, 3, 0, 3, 3, 0, 3, 2, 2, 1,\n",
              "         2, 0, 3, 0, 3, 2, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = M5(n_input=1, n_output=num_cls).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "x_batch, y_batch = next(iter(train_loader))\n",
        "outputs = model(x_batch.to(device))\n",
        "loss = loss_fn(outputs, y_batch.to(device))\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59eglXAfN3c0",
        "outputId": "ce7ced00-2c25-4956-d389-5efca7611b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.5067, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, test_loader, loss_fn):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss_valid = AverageMeter()\n",
        "        acc_test = Accuracy(task=\"multiclass\", num_classes=4).to(device)\n",
        "\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            acc_test.update(preds, targets.int())\n",
        "\n",
        "            loss_valid.update(loss.item())\n",
        "\n",
        "    return loss_valid.avg, acc_test.compute().item()"
      ],
      "metadata": {
        "id": "UA8cwzXPOLkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "lr = 0.01\n",
        "wd = 1e-3\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "\n",
        "\n",
        "loss_train_hist = []\n",
        "loss_test_hist = []\n",
        "\n",
        "acc_train_hist = []\n",
        "acc_test_hist = []\n",
        "\n",
        "best_loss_test = torch.inf\n",
        "epoch_counter = 0\n",
        "\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model, loss_train, acc_train = train_one_epoch(model,\n",
        "                                                 train_loader,\n",
        "                                                 loss_fn,\n",
        "                                                 optimizer,\n",
        "                                                 epoch)\n",
        "  loss_valid, acc_test = validation(model,\n",
        "                                     test_loader,\n",
        "                                     loss_fn)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_test_hist.append(loss_valid)\n",
        "\n",
        "  acc_train_hist.append(acc_train)\n",
        "  acc_test_hist.append(acc_test)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Acc = {acc_test:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSZ4l2ulN9He",
        "outputId": "011f623f-3d01-4221-8a95-9206b64f0c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.30batch/s, acc=0.344, loss=2.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 3.403, Acc = 0.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.21batch/s, acc=0.682, loss=1.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 3.186, Acc = 0.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.49batch/s, acc=0.786, loss=1.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 2.955, Acc = 0.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.41batch/s, acc=0.932, loss=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 2.668, Acc = 0.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.18batch/s, acc=0.964, loss=0.765]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 2.399, Acc = 0.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.45batch/s, acc=0.974, loss=0.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 2.199, Acc = 0.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, acc=0.974, loss=0.344]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 1.754, Acc = 0.3125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.36batch/s, acc=0.99, loss=0.223]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 1.526, Acc = 0.375\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.47batch/s, acc=0.99, loss=0.151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 1.027, Acc = 0.5417\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.16batch/s, acc=0.99, loss=0.102]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 0.8379, Acc = 0.6667\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.49batch/s, acc=0.995, loss=0.0695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 0.611, Acc = 0.7708\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.19batch/s, acc=1, loss=0.0569]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.69, Acc = 0.6875\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.11batch/s, acc=0.995, loss=0.0536]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 0.451, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.47batch/s, acc=1, loss=0.046]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.7665, Acc = 0.7708\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.16batch/s, acc=1, loss=0.0371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5531, Acc = 0.7708\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.46batch/s, acc=1, loss=0.0351]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5334, Acc = 0.8333\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.31batch/s, acc=1, loss=0.0291]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.534, Acc = 0.7708\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.37batch/s, acc=1, loss=0.0219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4549, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.42batch/s, acc=1, loss=0.0207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4916, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.13batch/s, acc=1, loss=0.0154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5855, Acc = 0.8333\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.44batch/s, acc=1, loss=0.0152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 0.4058, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.37batch/s, acc=1, loss=0.0125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 0.3934, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.29batch/s, acc=1, loss=0.0167]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4958, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.46batch/s, acc=1, loss=0.0124]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4304, Acc = 0.7708\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.12batch/s, acc=1, loss=0.0125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4485, Acc = 0.8542\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.49batch/s, acc=1, loss=0.013]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4688, Acc = 0.75\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.43batch/s, acc=1, loss=0.0111]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4416, Acc = 0.8333\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.25batch/s, acc=1, loss=0.0118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4303, Acc = 0.7708\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.45batch/s, acc=1, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 0.3813, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.16batch/s, acc=1, loss=0.0174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 1.391, Acc = 0.7083\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.47batch/s, acc=1, loss=0.0219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 1.557, Acc = 0.7708\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.45batch/s, acc=1, loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4664, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.20batch/s, acc=1, loss=0.014]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.418, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.42batch/s, acc=1, loss=0.0153]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5884, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.28batch/s, acc=1, loss=0.0124]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5611, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.40batch/s, acc=1, loss=0.0105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5205, Acc = 0.8333\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.48batch/s, acc=1, loss=0.0115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5086, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.11batch/s, acc=1, loss=0.00963]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.6201, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.48batch/s, acc=1, loss=0.00905]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.3947, Acc = 0.7917\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.32batch/s, acc=1, loss=0.00883]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4541, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.33batch/s, acc=1, loss=0.00797]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5909, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.44batch/s, acc=1, loss=0.00855]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5833, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.13batch/s, acc=1, loss=0.0078]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.3926, Acc = 0.875\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.47batch/s, acc=1, loss=0.00675]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.3878, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.39batch/s, acc=1, loss=0.00739]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5904, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.28batch/s, acc=1, loss=0.00702]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.5529, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.42batch/s, acc=1, loss=0.00651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4056, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.21batch/s, acc=1, loss=0.00647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4674, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.44batch/s, acc=1, loss=0.00537]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4648, Acc = 0.8125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:04<00:00,  1.47batch/s, acc=1, loss=0.00528]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 0.4324, Acc = 0.7917\n",
            "\n"
          ]
        }
      ]
    }
  ]
}